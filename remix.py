# ==============================================================================
# PROJETO: 
#  - Ferramenta de Processamento de Sinal
# ==============================================================================
#
# AUTOR: Jo√£o Pedro Hamata - 13672001
# DATA: 02/07/2025
#
# ==============================================================================

# Imports de Bibliotecas
import gradio as gr
import numpy as np
import torch
import torchaudio
import scipy.signal
import scipy.ndimage
import matplotlib.pyplot as plt
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
from skimage.restoration import denoise_bilateral
import soundfile as sf
import warnings
import gc
import psutil
import threading
import time
from contextlib import contextmanager
import traceback
from functools import wraps

# --- Configura√ß√µes Globais ---
warnings.filterwarnings("ignore")

# Configura√ß√µes de mem√≥ria e processamento
MAX_AUDIO_DURATION = 180  # segundos
MAX_IMAGE_SIZE = 2048  # pixels m√°ximos por dimens√£o
MAX_MEMORY_USAGE = 85  # % m√°ximo de uso de mem√≥ria
CHUNK_SIZE = 44100 * 10  # 10 segundos de √°udio por chunk

# Device detection com fallback robusto
def get_device():
    try:
        if torch.cuda.is_available():
            # Testa se CUDA est√° realmente funcionando
            test_tensor = torch.randn(10, device='cuda')
            del test_tensor
            torch.cuda.empty_cache()
            return torch.device("cuda:0")
    except:
        pass
    return torch.device("cpu")

DEVICE = get_device()
print(f"Usando dispositivo: {DEVICE}")
plt.style.use('seaborn-v0_8-darkgrid')

# ==============================================================================
# 1. UTILIT√ÅRIOS DE GERENCIAMENTO DE RECURSOS
# ==============================================================================

def check_memory_usage():
    """Verifica o uso atual de mem√≥ria do sistema."""
    return psutil.virtual_memory().percent

def clear_gpu_memory():
    """Limpa a mem√≥ria da GPU se dispon√≠vel."""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

def clear_memory():
    """For√ßa limpeza de mem√≥ria."""
    gc.collect()
    clear_gpu_memory()

@contextmanager
def memory_monitor():
    """Context manager para monitorar uso de mem√≥ria."""
    initial_memory = check_memory_usage()
    try:
        yield
    finally:
        current_memory = check_memory_usage()
        if current_memory > MAX_MEMORY_USAGE:
            clear_memory()
            print(f"Mem√≥ria liberada: {initial_memory}% -> {check_memory_usage()}%")

def safe_execution(func):
    """Decorator para execu√ß√£o segura com tratamento de erros."""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            with memory_monitor():
                return func(*args, **kwargs)
        except MemoryError:
            clear_memory()
            raise gr.Error("Mem√≥ria insuficiente. Tente com arquivos menores ou use a fun√ß√£o Reset.")
        except Exception as e:
            error_msg = f"Erro: {str(e)}"
            print(f"Erro detalhado: {traceback.format_exc()}")
            raise gr.Error(error_msg)
    return wrapper

def validate_audio(audio_data):
    """Valida e normaliza dados de √°udio."""
    if not isinstance(audio_data, tuple) or len(audio_data) != 2:
        raise ValueError("Formato de √°udio inv√°lido")
    
    sr, audio = audio_data
    if sr <= 0:
        raise ValueError("Sample rate inv√°lido")
    
    # Converte para numpy se necess√°rio
    if isinstance(audio, torch.Tensor):
        audio = audio.cpu().numpy()
    
    audio = np.asarray(audio, dtype=np.float32)
    
    # Verifica dura√ß√£o
    duration = len(audio) / sr
    if duration > MAX_AUDIO_DURATION:
        raise ValueError(f"√Åudio muito longo ({duration:.1f}s). M√°ximo: {MAX_AUDIO_DURATION}s")
    
    # Normaliza amplitude
    if np.max(np.abs(audio)) > 0:
        audio = audio / np.max(np.abs(audio)) * 0.95
    
    return (sr, audio)

def validate_image(image_data):
    """Valida e redimensiona imagem se necess√°rio."""
    if image_data is None:
        raise ValueError("Imagem inv√°lida")
    
    img = np.asarray(image_data)
    
    # Verifica dimens√µes
    if img.ndim not in [2, 3]:
        raise ValueError("Imagem deve ter 2 ou 3 dimens√µes")
    
    # Redimensiona se muito grande
    if img.shape[0] > MAX_IMAGE_SIZE or img.shape[1] > MAX_IMAGE_SIZE:
        from skimage.transform import resize
        scale = MAX_IMAGE_SIZE / max(img.shape[:2])
        new_shape = (int(img.shape[0] * scale), int(img.shape[1] * scale))
        if img.ndim == 3:
            new_shape += (img.shape[2],)
        img = resize(img, new_shape, preserve_range=True, anti_aliasing=True)
        img = img.astype(np.uint8)
        print(f"Imagem redimensionada para {new_shape[:2]}")
    
    return img

# ==============================================================================
# 2. WORKSPACE E FUN√á√ïES DE PROCESSAMENTO
# ==============================================================================

def create_initial_workspace():
    """Cria um dicion√°rio de estado inicial para o workspace."""
    return {
        "original": None, 
        "noisy": None, 
        "processed": None, 
        "separated": {},
        "metadata": {"type": None, "size": None, "duration": None}
    }

@safe_execution
def reset_workspace():
    """Reseta completamente o workspace e libera mem√≥ria."""
    clear_memory()
    return (
        create_initial_workspace(),
        # Limpa todas as visualiza√ß√µes
        None, None, None,  # imagens
        None, None, None,  # √°udios
        None, None, None,  # espectrogramas
        "",  # m√©tricas
        *[gr.update(value=None, visible=False) for _ in range(4)],  # separa√ß√£o
        gr.update(value="üîÑ Workspace resetado com sucesso!")
    )

def sdr_numpy(reference, estimate, epsilon=1e-8):
    """Calcula SDR de forma mais robusta."""
    try:
        ref, est = np.asarray(reference, dtype=np.float32), np.asarray(estimate, dtype=np.float32)
        
        # Converte para mono se necess√°rio
        if ref.ndim > 1: 
            ref = np.mean(ref, axis=1 if ref.shape[1] < ref.shape[0] else 0)
        if est.ndim > 1: 
            est = np.mean(est, axis=1 if est.shape[1] < est.shape[0] else 0)
        
        # Sincroniza comprimentos
        min_len = min(ref.shape[0], est.shape[0])
        ref, est = ref[:min_len], est[:min_len]
        
        if min_len == 0:
            return -np.inf
        
        # Calcula SDR
        alpha = np.dot(est, ref) / (np.dot(ref, ref) + epsilon)
        s_target = alpha * ref
        e_noise = est - s_target
        
        pow_s_target = np.sum(s_target**2)
        pow_e_noise = np.sum(e_noise**2)
        
        if pow_s_target == 0:
            return -np.inf
        
        sdr_val = 10 * np.log10(pow_s_target / (pow_e_noise + epsilon) + epsilon)
        return np.clip(sdr_val, -50, 50)  # Limita valores extremos
    except:
        return -np.inf

@safe_execution
def plot_spectrogram(audio, sr, title="Espectrograma"):
    """Plota espectrograma de forma mais eficiente."""
    if audio is None: 
        return None
    
    try:
        # Converte para mono e reduz tamanho se necess√°rio
        audio_mono = np.mean(audio, axis=1) if audio.ndim > 1 else audio
        
        # Reduz resolu√ß√£o para √°udios longos
        if len(audio_mono) > CHUNK_SIZE:
            step = len(audio_mono) // CHUNK_SIZE
            audio_mono = audio_mono[::step]
            sr = sr // step
        
        # Calcula STFT com par√¢metros otimizados
        nperseg = min(2048, len(audio_mono) // 4)
        noverlap = nperseg // 4 * 3
        
        f, t, Zxx = scipy.signal.stft(audio_mono, fs=sr, nperseg=nperseg, noverlap=noverlap)
        
        # Converte para dB com clipping
        db_spec = 20 * np.log10(np.abs(Zxx) + 1e-9)
        
        # Cria plot
        fig, ax = plt.subplots(figsize=(10, 4))
        
        # Limita range din√¢mico
        vmin = np.max(db_spec) - 80
        vmax = np.max(db_spec)
        
        mesh = ax.pcolormesh(t, f, db_spec, shading='gouraud', cmap='magma', 
                           vmin=vmin, vmax=vmax)
        
        ax.set(yscale='log', ylim=(20, sr/2), 
               xlabel="Tempo (s)", ylabel="Frequ√™ncia (Hz)", title=title)
        
        fig.colorbar(mesh, ax=ax, format='%+2.0f dB')
        plt.tight_layout()
        
        return fig
    except Exception as e:
        print(f"Erro no espectrograma: {e}")
        return None

@safe_execution
def add_noise_to_data(data, noise_type, intensity):
    """Adiciona ru√≠do aos dados de forma mais robusta."""
    if data is None: 
        return None
    
    try:
        if isinstance(data, np.ndarray) and data.ndim == 3:  # Imagem
            data = validate_image(data)
            img = data.astype(np.float32)
            amount = intensity / 100.0
            
            if noise_type == "Gaussiano":
                noise_std = amount * 50
                noise = np.random.normal(0, noise_std, img.shape)
                noisy = img + noise
            else:  # Sal e Pimenta
                noisy = np.copy(img)
                s_vs_p = 0.5
                
                # Sal
                num_salt = int(amount * img.size * s_vs_p)
                coords = tuple(np.random.randint(0, i-1, num_salt) for i in img.shape)
                noisy[coords] = 255
                
                # Pimenta
                num_pepper = int(amount * img.size * (1. - s_vs_p))
                coords = tuple(np.random.randint(0, i-1, num_pepper) for i in img.shape)
                noisy[coords] = 0
            
            return np.clip(noisy, 0, 255).astype(np.uint8)
            
        elif isinstance(data, tuple) and len(data) == 2:  # √Åudio
            sr, audio = validate_audio(data)
            amount = intensity / 100.0
            
            # Adiciona ru√≠do gaussiano
            noise = np.random.normal(0, np.std(audio) * amount * 2, audio.shape)
            noisy_audio = audio + noise
            
            # Normaliza para evitar clipping
            if np.max(np.abs(noisy_audio)) > 1.0:
                noisy_audio = noisy_audio / np.max(np.abs(noisy_audio)) * 0.95
            
            return (sr, noisy_audio.astype(np.float32))
    except Exception as e:
        raise gr.Error(f"Erro ao adicionar ru√≠do: {str(e)}")
    
    return data

@safe_execution
def run_denoise(data, f_type, k_size, g_sigma, w_noise, b_sigma_s, b_sigma_c, original_data):
    """Executa denoising de forma mais robusta."""
    if data is None: 
        raise gr.Error("Execute o Passo 1 para adicionar ru√≠do antes de aplicar o denoising.")
    
    try:
        if isinstance(data, np.ndarray) and data.ndim == 3:  # Imagem
            img = data.copy()
            k = int(k_size) // 2 * 2 + 1  # Garante kernel √≠mpar
            
            if f_type == "Gaussiano":
                proc = scipy.ndimage.gaussian_filter(img, sigma=g_sigma).astype(np.uint8)
            elif f_type == "Mediana":
                proc = scipy.ndimage.median_filter(img, size=k).astype(np.uint8)
            elif f_type == "Wiener (Imagem)":
                # Aplica Wiener por canal
                proc_channels = []
                for i in range(3):
                    channel = scipy.signal.wiener(img[:,:,i], k, w_noise)
                    proc_channels.append(channel)
                proc = np.clip(np.stack(proc_channels, axis=2), 0, 255).astype(np.uint8)
            elif f_type == "Bilateral (Imagem)":
                proc = (denoise_bilateral(img, sigma_color=b_sigma_c, 
                                        sigma_spatial=b_sigma_s, channel_axis=-1) * 255).astype(np.uint8)
            
            # Calcula m√©tricas
            psnr_val = psnr(original_data, proc)
            ssim_val = ssim(original_data, proc, channel_axis=-1)
            metrics = f"PSNR: {psnr_val:.2f} dB\nSSIM: {ssim_val:.4f}"
            
            return proc, metrics
            
        elif isinstance(data, tuple) and len(data) == 2:  # √Åudio
            sr, audio = validate_audio(data)
            k = int(k_size) // 2 * 2 + 1
            
            # Converte para mono para processamento
            audio_mono = np.mean(audio, axis=1) if audio.ndim > 1 else audio
            
            # STFT com par√¢metros adaptativos
            nperseg = min(2048, len(audio_mono) // 4)
            noverlap = nperseg // 4 * 3
            
            f, t, Zxx = scipy.signal.stft(audio_mono, fs=sr, nperseg=nperseg, noverlap=noverlap)
            mag, phase = np.abs(Zxx), np.angle(Zxx)
            
            # Aplica filtro na magnitude
            if f_type == "Gaussiano":
                mag_filt = scipy.ndimage.gaussian_filter(mag, sigma=g_sigma)
            else:
                mag_filt = scipy.ndimage.median_filter(mag, size=k)
            
            # Reconstr√≥i sinal
            Zxx_recon = mag_filt * np.exp(1j * phase)
            _, audio_proc = scipy.signal.istft(Zxx_recon, fs=sr, nperseg=nperseg, noverlap=noverlap)
            
            # Garante mesmo tamanho do original
            if len(audio_proc) != len(audio_mono):
                audio_proc = np.resize(audio_proc, len(audio_mono))
            
            # Calcula SDR
            original_sr, original_audio = original_data
            original_mono = np.mean(original_audio, axis=1) if original_audio.ndim > 1 else original_audio
            sdr_val = sdr_numpy(original_mono, audio_proc)
            
            metrics = f"SDR: {sdr_val:.2f} dB"
            
            return (sr, audio_proc.astype(np.float32)), metrics
            
    except Exception as e:
        raise gr.Error(f"Erro no denoising: {str(e)}")
    
    return None, "Tipo de dado n√£o suportado."

# ==============================================================================
# 3. M√ìDULOS DE SEPARA√á√ÉO DE FONTES
# ==============================================================================

@safe_execution
def run_classical_separation(audio_tuple, h_len, p_len):
    """Separa√ß√£o cl√°ssica com melhor tratamento de erros."""
    if not isinstance(audio_tuple, tuple): 
        raise gr.Error("Separa√ß√£o Cl√°ssica requer um input de √°udio. Por favor, carregue um √°udio.")
    
    try:
        sr, audio = validate_audio(audio_tuple)
        audio_mono = np.mean(audio, axis=1) if audio.ndim > 1 else audio
        
        # Par√¢metros adaptativos para STFT
        nperseg = min(2048, len(audio_mono) // 4)
        noverlap = nperseg // 4 * 3
        
        f, t, Zxx = scipy.signal.stft(audio_mono, fs=sr, nperseg=nperseg, noverlap=noverlap)
        mag = np.abs(Zxx)
        
        # Filtros morfol√≥gicos
        h_len_int, p_len_int = max(1, int(h_len)), max(1, int(p_len))
        
        mag_h = scipy.ndimage.grey_opening(mag, size=(1, h_len_int))
        mag_p = scipy.ndimage.grey_opening(mag, size=(p_len_int, 1))
        
        # M√°scaras de separa√ß√£o
        mask_h = mag_h / (mag_h + mag_p + 1e-8)
        mask_p = mag_p / (mag_h + mag_p + 1e-8)
        
        # Reconstr√≥i sinais
        _, audio_h = scipy.signal.istft(Zxx * mask_h, fs=sr, nperseg=nperseg, noverlap=noverlap)
        _, audio_p = scipy.signal.istft(Zxx * mask_p, fs=sr, nperseg=nperseg, noverlap=noverlap)
        
        return (
            gr.update(value=(sr, audio_h.astype(np.float32)), label="Harm√¥nico", visible=True),
            gr.update(value=(sr, audio_p.astype(np.float32)), label="Percussivo", visible=True),
            gr.update(visible=False), 
            gr.update(visible=False)
        )
    except Exception as e:
        raise gr.Error(f"Erro na separa√ß√£o cl√°ssica: {str(e)}")

# Cache global para modelo
hdemucs_bundle = None
hdemucs_model = None

def get_hdemucs_bundle():
    """Carrega bundle HDEMUCS com cache."""
    global hdemucs_bundle
    if hdemucs_bundle is None:
        try:
            hdemucs_bundle = torchaudio.pipelines.HDEMUCS_HIGH_MUSDB_PLUS
        except Exception as e:
            raise gr.Error(f"Erro ao carregar modelo HDEMUCS: {str(e)}")
    return hdemucs_bundle

def get_hdemucs_model():
    """Carrega modelo HDEMUCS com cache."""
    global hdemucs_model
    if hdemucs_model is None:
        try:
            bundle = get_hdemucs_bundle()
            hdemucs_model = bundle.get_model().to(DEVICE)
            hdemucs_model.eval()  # Modo de avalia√ß√£o
        except Exception as e:
            clear_gpu_memory()
            raise gr.Error(f"Erro ao carregar modelo: {str(e)}")
    return hdemucs_model

def separate_sources_dl(model, mix, model_sr, seg=10.0, ov=0.1, dev=DEVICE):
    """Separa√ß√£o de fontes com processamento em chunks para economizar mem√≥ria."""
    try:
        b, c, l = mix.shape
        chunk_l = int(model_sr * seg * (1 + ov))
        start, end = 0, chunk_l
        ov_f = int(ov * model_sr)
        
        fade = torchaudio.transforms.Fade(0, ov_f, "linear")
        final = torch.zeros(b, len(model.sources), c, l, device=dev)
        
        while start < l - ov_f:
            chunk = mix[:, :, start:end]
            
            # Processa chunk com limpeza de mem√≥ria
            with torch.no_grad():
                out = model.forward(chunk.to(dev))
                if start > 0:  # Limpa chunks anteriores da GPU
                    del chunk
                    clear_gpu_memory()
            
            out = fade(out)
            final[:, :, :, start:end] += out.cpu()  # Move para CPU
            del out
            
            if start == 0:
                fade.fade_in_len = ov_f
            
            start += chunk_l - ov_f
            end += chunk_l - ov_f
            
            if end >= l:
                fade.fade_out_len = 0
        
        return final
    except torch.cuda.OutOfMemoryError:
        clear_gpu_memory()
        raise gr.Error("Mem√≥ria GPU insuficiente. Tente com √°udio mais curto.")
    except Exception as e:
        raise gr.Error(f"Erro na separa√ß√£o: {str(e)}")

@safe_execution
def run_dl_separation(audio_tuple, progress=gr.Progress()):
    """Separa√ß√£o deep learning com melhor gest√£o de recursos."""
    if not isinstance(audio_tuple, tuple): 
        raise gr.Error("Separa√ß√£o Deep Learning requer um input de √°udio. Por favor, carregue um √°udio.")
    
    try:
        progress(0, desc="Carregando modelo...")
        
        # Carrega modelo e configura√ß√µes
        bundle = get_hdemucs_bundle()
        model = get_hdemucs_model()
        model_sr = bundle.sample_rate
        
        progress(0.1, desc="Preparando √°udio...")
        
        sr, audio = validate_audio(audio_tuple)
        wave = torch.from_numpy(audio.T.astype(np.float32))
        
        # Reamostra se necess√°rio
        if sr != model_sr:
            wave = torchaudio.functional.resample(wave, sr, model_sr)
        
        if wave.ndim == 1:
            wave = wave.unsqueeze(0)
        
        # Normaliza√ß√£o robusta
        ref = wave.mean(0)
        wave_std = ref.std()
        if wave_std > 0:
            wave = (wave - ref.mean()) / wave_std
        
        progress(0.3, desc="Separando fontes...")
        
        # Executa separa√ß√£o
        sources = separate_sources_dl(model, wave[None], model_sr=model_sr)[0]
        
        progress(0.9, desc="Finalizando...")
        
        # Desnormaliza
        if wave_std > 0:
            sources = sources * wave_std + ref.mean()
        
        # Converte para numpy e CPU
        results = []
        for s, n in zip(sources, model.sources):
            audio_np = s.cpu().numpy().T
            results.append(gr.update(value=(model_sr, audio_np), label=n.capitalize(), visible=True))
        
        # Preenche slots vazios
        while len(results) < 4:
            results.append(gr.update(visible=False))
        
        progress(1, desc="Conclu√≠do!")
        clear_memory()  # Limpa mem√≥ria ao final
        
        return results
        
    except Exception as e:
        clear_memory()
        raise gr.Error(f"Erro na separa√ß√£o DL: {str(e)}")

# ==============================================================================
# 4. CONSTRU√á√ÉO DA INTERFACE GR√ÅFICA (UI/UX)
# ==============================================================================

with gr.Blocks(theme=gr.themes.Monochrome(), title="Remix Studio") as demo:
    ws = gr.State(create_initial_workspace)
    
    # Cabe√ßalho com informa√ß√µes do sistema
    with gr.Row():
        gr.Markdown("# üéπ Remix Studio: Ferramenta de Processamento de Sinal (v2.0)")
        with gr.Column(scale=1):
            system_info = gr.Markdown(f"**Sistema:** {DEVICE} | **Mem√≥ria:** {check_memory_usage():.1f}%")
            reset_btn = gr.Button("üîÑ Reset Workspace", variant="secondary", size="sm")
    
    # Status e alertas
    status_message = gr.Markdown("‚úÖ Sistema pronto. Carregue seus dados para come√ßar.", visible=True)
    
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### Passo 1: Carregar Dados e Adicionar Ru√≠do")
            
            input_img = gr.Image(
                type="numpy",
                label="Input de Imagem"
            )
            gr.Markdown(f"M√°ximo: {MAX_IMAGE_SIZE}x{MAX_IMAGE_SIZE} pixels")

            input_audio = gr.Audio(
                type="numpy",
                label="Input de √Åudio",
                sources=["upload", "microphone"]
            )
            gr.Markdown(f"M√°ximo: {MAX_AUDIO_DURATION}s")
            
            with gr.Accordion("Configura√ß√µes de Ru√≠do", open=True):
                noise_type = gr.Radio(
                    ["Gaussiano", "Sal e Pimenta"], 
                    value="Gaussiano", 
                    label="Tipo (Imagem)"
                )
                noise_intensity = gr.Slider(
                    0, 100, 10, 
                    label="Intensidade (%)",
                    info="Intensidade do ru√≠do a ser adicionado"
                )
            
            prepare_btn = gr.Button("üéØ Preparar Workspace & Adicionar Ru√≠do", variant="primary")
            
        with gr.Column(scale=2):
            gr.Markdown("### Visualizadores")
            with gr.Tabs():
                with gr.TabItem("üñº Imagem"):
                    with gr.Row():
                        img_view_orig = gr.Image(label="Original", interactive=False)
                        img_view_noisy = gr.Image(label="Com Ru√≠do", interactive=False)
                        img_view_proc = gr.Image(label="Processada", interactive=False)
                        
                with gr.TabItem("üé§ √Åudio"):
                    with gr.Accordion("Players de √Åudio", open=False):
                        with gr.Row():
                            audio_view_orig = gr.Audio(label="Original", interactive=False)
                            audio_view_noisy = gr.Audio(label="Com Ru√≠do", interactive=False)
                            audio_view_proc = gr.Audio(label="Processado", interactive=False)
                    with gr.Row():
                        spec_view_orig = gr.Plot(label="Espectrograma Original")
                        spec_view_noisy = gr.Plot(label="Espectrograma Com Ru√≠do")  
                        spec_view_proc = gr.Plot(label="Espectrograma Processado")
    
    gr.Markdown("### Passo 2: Aplicar Ferramentas de Processamento")
    
    with gr.Tabs():
        with gr.TabItem("üõ† Denoising Tools"):
            with gr.Row():
                with gr.Column():
                    denoise_filter_type = gr.Dropdown(
                        ["Gaussiano", "Mediana", "Wiener (Imagem)", "Bilateral (Imagem)"], 
                        value="Gaussiano", 
                        label="Filtro",
                        info="Escolha o tipo de filtro para denoising"
                    )
                    
                    # Par√¢metros condicionais
                    with gr.Row(visible=True) as gaussian_params:
                        denoise_sigma_gauss = gr.Slider(0.1, 10.0, 1.0, label="Sigma (Intensidade)")
                    
                    with gr.Row(visible=False) as median_params:
                        denoise_kernel_size_median = gr.Slider(3, 21, 5, step=2, label="Tamanho do Kernel")
                    
                    with gr.Row(visible=False) as wiener_params:
                        denoise_kernel_size_wiener = gr.Slider(3, 21, 5, step=2, label="Tamanho do Kernel")
                        denoise_noise_wiener = gr.Slider(0.1, 1000, 10.0, label="Vari√¢ncia do Ru√≠do")
                    
                    with gr.Row(visible=False) as bilateral_params:
                        denoise_sigma_s = gr.Slider(1, 30, 15, label="Sigma Espacial")
                        denoise_sigma_c = gr.Slider(0.01, 0.5, 0.1, label="Sigma Cor/Intensidade")
                    
                    run_denoise_btn = gr.Button("üîß Aplicar Denoise", variant="primary")
                    
                with gr.Column():
                    metrics_label = gr.Label(label="M√©tricas de Desempenho", value="")

        with gr.TabItem("üéõ Ferramentas de Separa√ß√£o de Fontes (√Åudio)"):
            with gr.Row():
                with gr.Column():
                    gr.Markdown("#### üéµ Separa√ß√£o Cl√°ssica (Morfol√≥gica)")
                    gr.Markdown("*R√°pida e eficiente para separa√ß√£o harm√¥nico/percussivo*")
                    
                    h_len = gr.Slider(1, 100, 30, label="Filtro Harm√¥nico", 
                                    info="Comprimento do filtro para componentes harm√¥nicos")
                    p_len = gr.Slider(1, 100, 30, label="Filtro Percussivo",
                                    info="Comprimento do filtro para componentes percussivos")
                    run_classical_sep_btn = gr.Button("üéº Separar Harm√¥nico/Percussivo")
                    
                with gr.Column():
                    gr.Markdown("#### ü§ñ Separa√ß√£o Deep Learning (Pr√©-treinado)")
                    gr.Markdown("*Separa√ß√£o avan√ßada com IA - requer mais recursos*")
                    
                    gr.Markdown("**Fontes separadas:** Vocais, Baixo, Bateria, Outros")
                    memory_warning = gr.Markdown(
                        "‚ö†Ô∏è **Aten√ß√£o:** Processo intensivo. √Åudios longos podem usar muita mem√≥ria.",
                        visible=True
                    )
                    run_dl_sep_btn = gr.Button("üöÄ Separar com IA", variant="primary")
            
            gr.Markdown("#### üé∂ Sa√≠das da Separa√ß√£o")
            with gr.Row():
                separated_outputs_audio = [
                    gr.Audio(label=f"Faixa {i+1}", visible=False, interactive=False) 
                    for i in range(4)
                ]

    # ==============================================================================
    # 5. L√ìGICA DE EVENTOS DA UI
    # ==============================================================================
    
    # Eventos de reset e limpeza
    def update_system_info():
        """Atualiza informa√ß√µes do sistema."""
        memory_usage = check_memory_usage()
        color = "üü¢" if memory_usage < 70 else "üü°" if memory_usage < 85 else "üî¥"
        return f"**Sistema:** {DEVICE} | **Mem√≥ria:** {color} {memory_usage:.1f}%"
    
    # Reset workspace
    reset_btn.click(
        reset_workspace,
        outputs=[
            ws, img_view_orig, img_view_noisy, img_view_proc,
            audio_view_orig, audio_view_noisy, audio_view_proc,
            spec_view_orig, spec_view_noisy, spec_view_proc,
            metrics_label, *separated_outputs_audio, status_message
        ]
    )
    
    # Mutual exclusion entre inputs
    def clear_audio_input():
        return gr.update(value=None)
    
    def clear_image_input():
        return gr.update(value=None)
    
    input_img.change(clear_audio_input, outputs=input_audio)
    input_audio.change(clear_image_input, outputs=input_img)
    
    # Atualiza√ß√£o peri√≥dica do sistema (a cada 10 segundos)
    def periodic_update():
        return update_system_info()
    
    update_btn = gr.Button("Atualizar sistema")
    update_btn.click(periodic_update, outputs=system_info)
    
    # Prepara√ß√£o do workspace
    @safe_execution
    def prepare_workspace_and_add_noise(ws_dict, img, audio, noise_t, noise_i):
        """Prepara workspace e adiciona ru√≠do com valida√ß√£o robusta."""
        # Limpa workspace anterior
        ws_dict = create_initial_workspace()
        
        # Determina tipo de dado
        data = img if img is not None else audio
        if data is None: 
            raise gr.Error("Por favor, carregue uma imagem ou √°udio primeiro.")
        
        # Valida e armazena dados originais
        if isinstance(data, np.ndarray):  # Imagem
            data = validate_image(data)
            ws_dict["metadata"] = {
                "type": "image", 
                "size": data.shape[:2], 
                "duration": None
            }
        else:  # √Åudio
            data = validate_audio(data)
            sr, audio_data = data
            ws_dict["metadata"] = {
                "type": "audio", 
                "size": audio_data.shape, 
                "duration": len(audio_data) / sr
            }
        
        ws_dict["original"] = data
        
        # Adiciona ru√≠do
        noisy_data = add_noise_to_data(data, noise_t, noise_i)
        ws_dict["noisy"] = noisy_data
        
        # Prepara sa√≠das baseadas no tipo
        if isinstance(data, np.ndarray):  # Imagem
            status = f"‚úÖ Imagem carregada: {data.shape[0]}x{data.shape[1]} pixels"
            return (
                ws_dict, data, noisy_data, None, None, None, 
                None, None, None, status
            )
        else:  # √Åudio
            sr, orig_audio = data
            sr_n, noisy_audio = noisy_data
            
            # Gera espectrogramas
            plot_orig = plot_spectrogram(orig_audio, sr, "Original")
            plot_noisy = plot_spectrogram(noisy_audio, sr_n, "Com Ru√≠do")
            
            duration = len(orig_audio) / sr
            status = f"‚úÖ √Åudio carregado: {duration:.1f}s, {sr}Hz"
            
            return (
                ws_dict, None, None, data, noisy_data, None,
                plot_orig, plot_noisy, None, status
            )
    
    prepare_btn.click(
        prepare_workspace_and_add_noise,
        inputs=[ws, input_img, input_audio, noise_type, noise_intensity],
        outputs=[
            ws, img_view_orig, img_view_noisy, audio_view_orig, 
            audio_view_noisy, audio_view_proc, spec_view_orig, 
            spec_view_noisy, spec_view_proc, status_message
        ]
    )
    
    # Processamento de denoising
    @safe_execution
    def process_denoise_click(ws_dict, f_type, s_g, k_m, k_w, n_w, s_s, s_c):
        """Processa denoising com tratamento de erros."""
        if ws_dict["noisy"] is None:
            raise gr.Error("Nenhum dado com ru√≠do encontrado. Execute o Passo 1 primeiro.")
        
        # Determina par√¢metros baseados no tipo de filtro
        k_size = k_m if f_type == "Mediana" else (k_w if f_type == "Wiener (Imagem)" else 3)
        
        # Executa denoising
        processed_data, metrics = run_denoise(
            ws_dict["noisy"], f_type, k_size, s_g, n_w, s_s, s_c, ws_dict["original"]
        )
        
        ws_dict["processed"] = processed_data
        
        # Prepara sa√≠das
        if isinstance(processed_data, np.ndarray):  # Imagem
            status = "‚úÖ Denoising de imagem conclu√≠do"
            return ws_dict, processed_data, None, None, metrics, status
        else:  # √Åudio
            plot_proc = plot_spectrogram(processed_data[1], processed_data[0], "Processado")
            status = "‚úÖ Denoising de √°udio conclu√≠do"
            return ws_dict, None, processed_data, plot_proc, metrics, status
    
    denoise_inputs = [
        ws, denoise_filter_type, denoise_sigma_gauss, denoise_kernel_size_median,
        denoise_kernel_size_wiener, denoise_noise_wiener, denoise_sigma_s, denoise_sigma_c
    ]
    
    run_denoise_btn.click(
        process_denoise_click,
        inputs=denoise_inputs,
        outputs=[ws, img_view_proc, audio_view_proc, spec_view_proc, metrics_label, status_message]
    )
    
    # Toggle de par√¢metros de denoising
    def toggle_denoise_params(f_type):
        """Mostra/oculta par√¢metros baseados no tipo de filtro."""
        return (
            gr.update(visible=f_type == "Gaussiano"),
            gr.update(visible=f_type == "Mediana"),
            gr.update(visible=f_type == "Wiener (Imagem)"),
            gr.update(visible=f_type == "Bilateral (Imagem)")
        )
    
    denoise_filter_type.change(
        toggle_denoise_params,
        inputs=denoise_filter_type,
        outputs=[gaussian_params, median_params, wiener_params, bilateral_params]
    )
    
    # Separa√ß√£o cl√°ssica
    @safe_execution
    def classical_separation_wrapper(ws_dict, h_len, p_len):
        """Wrapper para separa√ß√£o cl√°ssica."""
        # Determina √°udio a processar
        audio_to_process = ws_dict.get('processed') or ws_dict.get('noisy') or ws_dict.get('original')
        
        if audio_to_process is None:
            raise gr.Error("Nenhum √°udio carregado no workspace.")
        
        if not isinstance(audio_to_process, tuple):
            raise gr.Error("Separa√ß√£o cl√°ssica requer dados de √°udio.")
        
        return run_classical_separation(audio_to_process, h_len, p_len)
    
    run_classical_sep_btn.click(
        classical_separation_wrapper,
        inputs=[ws, h_len, p_len],
        outputs=separated_outputs_audio
    )
    
    # Separa√ß√£o deep learning
    @safe_execution
    def dl_separation_wrapper(ws_dict, progress=gr.Progress()):
        """Wrapper para separa√ß√£o deep learning."""
        # Determina √°udio a processar
        audio_to_process = ws_dict.get('processed') or ws_dict.get('noisy') or ws_dict.get('original')
        
        if audio_to_process is None:
            raise gr.Error("Nenhum √°udio carregado no workspace.")
        
        if not isinstance(audio_to_process, tuple):
            raise gr.Error("Separa√ß√£o deep learning requer dados de √°udio.")
        
        # Verifica dura√ß√£o para alertar sobre recursos
        sr, audio = audio_to_process
        duration = len(audio) / sr
        
        if duration > 60:
            progress(0, desc=f"‚ö†Ô∏è √Åudio longo ({duration:.1f}s) - Isso pode demorar...")
        
        return run_dl_separation(audio_to_process, progress)
    
    run_dl_sep_btn.click(
        dl_separation_wrapper,
        inputs=[ws],
        outputs=separated_outputs_audio
    )
    
    # Valida√ß√£o de inputs em tempo real
    def validate_image_input(img):
        """Valida input de imagem em tempo real."""
        if img is None:
            return "üìÅ Carregue uma imagem"
        
        try:
            validated = validate_image(img)
            h, w = validated.shape[:2]
            size_mb = img.nbytes / (1024 * 1024)
            return f"‚úÖ Imagem v√°lida: {w}x{h} ({size_mb:.1f}MB)"
        except Exception as e:
            return f"‚ùå Erro: {str(e)}"
    
    def validate_audio_input(audio):
        """Valida input de √°udio em tempo real."""
        if audio is None:
            return "üìÅ Carregue um √°udio"
        
        try:
            validated = validate_audio(audio)
            sr, audio_data = validated
            duration = len(audio_data) / sr
            size_mb = audio_data.nbytes / (1024 * 1024)
            return f"‚úÖ √Åudio v√°lido: {duration:.1f}s, {sr}Hz ({size_mb:.1f}MB)"
        except Exception as e:
            return f"‚ùå Erro: {str(e)}"
    
    # Eventos de valida√ß√£o em tempo real
    input_img.change(
        lambda img: validate_image_input(img),
        inputs=input_img,
        outputs=status_message
    )
    
    input_audio.change(
        lambda audio: validate_audio_input(audio),
        inputs=input_audio,
        outputs=status_message
    )

# ==============================================================================
# 6. CONFIGURA√á√ïES DE INICIALIZA√á√ÉO E CLEANUP
# ==============================================================================

def cleanup_on_exit():
    """Limpa recursos ao sair."""
    global hdemucs_model, hdemucs_bundle
    
    try:
        if hdemucs_model is not None:
            del hdemucs_model
        if hdemucs_bundle is not None:
            del hdemucs_bundle
        clear_memory()
        print("üßπ Limpeza de recursos conclu√≠da")
    except:
        pass

import atexit
atexit.register(cleanup_on_exit)

# ==============================================================================
# 7. INICIALIZA√á√ÉO DO APLICATIVO
# ==============================================================================

if __name__ == "__main__":
    print("üéπ Iniciando Remix Studio v2.0...")
    print(f"üìä Sistema: {DEVICE}")
    print(f"üíæ Mem√≥ria inicial: {check_memory_usage():.1f}%")
    print(f"‚öôÔ∏è Configura√ß√µes:")
    print(f"   - Dura√ß√£o m√°xima de √°udio: {MAX_AUDIO_DURATION}s")
    print(f"   - Tamanho m√°ximo de imagem: {MAX_IMAGE_SIZE}px")
    print(f"   - Limite de mem√≥ria: {MAX_MEMORY_USAGE}%")
    
    try:
        demo.launch(
            server_name="0.0.0.0",
            server_port=7860,
            share=False,
            show_error=True,
            quiet=False,
            max_threads=4,  # Limita threads para controle de recursos
            favicon_path=None,
            ssl_verify=False
        )
    except KeyboardInterrupt:
        print("\nüõë Aplicativo interrompido pelo usu√°rio")
        cleanup_on_exit()
    except Exception as e:
        print(f"‚ùå Erro fatal: {e}")
        cleanup_on_exit()
    finally:
        print("üëã Remix Studio finalizado")
